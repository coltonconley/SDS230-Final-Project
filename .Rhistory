#Code here.   End up with code below
gunRanking <-  html_nodes(webpage,'p strong')
gunRanking <- html_text(gunRanking)
gunRanking <- gunRanking[c(2,4,6:53)]
gunRanking <- trimws(gunRanking)
gunRanking <- gsub(".*[.]", "", gunRanking)
gunRanking <- trimws(gunRanking)
gunRanking <- c(50:1)[order(gunRanking)]
#Create ammoRank variable.  This should be an INTEGER variable.
guns$ammoRank <- as.integer(gunRanking)
#Create new variable called Grade such that GiffordsGrade is recoded as follows:
#  Any form of A or B becomes 'AB'
#  Any form of C or D becomes 'CD'
#  F stays at F
guns$Grade <- recode(guns$GiffordsGrade, "'A' = 'AB'; 'A-' = 'AB'; 'B' = 'AB'; 'B+' = 'AB'; 'C' = 'CD'; 'C-' = 'CD'; 'C+' = 'CD'; 'D' = 'CD'; 'D-' = 'CD'; 'F' = 'F'")
#Change median income so that it is in thousands of dollars, not dollars.
guns$median.inc <- (guns$median.inc)/1000
#Create a variable that is the natural log of lawtotal.
guns$loglaws <- log(guns$lawtotal)
#Create a boxplot of rate_16 by Grade.  Add a title and change the color.
boxplot(guns$rate_16~guns$Grade, main = "Boxplot of Firearm Fatality Rate per 100k in 2016 by Grade", xlab = "Grade", ylab = "Rate", col = "orange")
#Calculate the standard deviation of rate_16 for each grade group
#print("SD by Genre")
(sds <- tapply(guns$rate_16, guns$Grade, sd))
#Get ratio of max to min sample standard deviation by Grade and round to one decimal place.
#print("Ratio of Max/Min Sample SD")
round(max(sds)/min(sds),1)
#Based on previous calculation, is the equal variance assumption of ANOVA reasonably met?  yes or no
(q104 <- "yes")
#Calculate a one-way ANOVA comparing mean rate_16 by Grade.  Use the aov() function.
(mod1 <- aov(guns$rate_16 ~ guns$Grade))
#Get summary of mod1
summary(mod1)
#Create Tukey confidence intervals for all pairs of groups.
TukeyHSD(mod1)
#Plot Tukey Confidence intervals.
plot(TukeyHSD(mod1), las=1)
#Use the myResPlots2 function to evaluate model assumptions for mod1.
myResPlots2(mod1, label = "Firearm Fatality Rate by Grade")
#Do the residuals seem approximately normally distributed?
#Does the plot of fits vs. residuals indicate any model lack of fit?
(q110 <- c("yes","no"))
#Perform a Kruskal-Wallis test to compare rate_16 based on Grade
kruskal.test(rate_16 ~ as.factor(Grade), data = guns)
#Fit a regression predicting lawtotal based on median.inc and ammoRank
(mod2 <- lm(lawtotal ~ median.inc + ammoRank, data = guns))
#Get summary information for mod2
summary(mod2)
#Run a Box Cox procedure on model q211
trans1 <- boxCox(mod2)
trans1$x[which.max(trans1$y)]
#What is a reasonable suggested value for lambda?  Replace 'lambda' below with a number.
(q214 <- c(0.1010101))
#Fit a regression model predicting the transformed version of lawtotal suggested by the Box Cox Transformation.
#  Again, median.inc and ammmoRank are the two predictors.
(mod3 <- lm((lawtotal)^q214 ~ median.inc + ammoRank, data = guns))
#Get summary information for model mod3.
summary(mod3)
#Are both predictors statistically significant at the 0.05 level?
(q217 <- c("yes"))
#According to the model mod3, as ammoRank increases, does the number of laws increase or decrease?
(q218 <- c("increase"))
#use myResPlots2 to get residual plots for this model.
myResPlots2(mod1, label = "Law by Median Inc and Ammo Rank")
#create an object q301 that only has the following columns of guns : rate_16, median.inc, loglaws, LawRanking, ammoRank.
q301 <- guns[,c("rate_16","median.inc","loglaws","LawRanking", "ammoRank")]
#Get correlations for the variables in q301 and round to two decimal places.
(round(cor(q301), 2))
#Create an object that has the results of cor.mtest for the columns of q301.  Use 95% CI.
(q303 <- cor.mtest(q301, conf.level = .95))
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values for the columns in q302.
corrplot.mixed(cor(q301), lower.col="black", upper = "ellipse", tl.col = "black", number.cex=.7, tl.pos = "lt", tl.cex=.7, p.mat = q303$p, sig.level = .05)
#Are the correlations you observe relatively strong or relatively weak?
(q305 <- c("relatively strong"))
#Use the parisJDRS() function on the columns of q301.
(q306 <- pairsJDRS(q301, labels = names(q301)))
names(guns)
#Create a dataframe guns2 from guns that removes state, code, rate_05, lawtotal, GiffordsGrade, Grade.
guns2 <- guns[,-c(1,2,4,25,27,29)]
#Run bests subsets to predict rate_16 based on all other columns in guns2 - use regsubsets() function.
(q401 <- regsubsets(rate_16 ~ ., data = guns2, nvmax = 23))
knitr::opts_chunk$set(echo = TRUE)
library(reshape)
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
BE <- read.csv("Average BE .csv")
size <- read.csv("Average Firm Size Monthly.csv")
returns <- read.csv("Average Weighted Returns Monthly.csv")
rf <- read.csv("RP-RF.csv")
#BE <- BE[complete.cases(BE),]
#size <- size[complete.cases(size),]
#returns <- returns[complete.cases(returns),]
BE[BE== -99.99] <- 0
size[size == -99.99] <- 0
returns[returns == -99.99] <- 0
rf[rf == -99.99] <- 0
size$Year <- substr(size$Year, 1, 4) #Strip off all ofthe month values
size <- aggregate(.~Year, data = size, mean)
returns$Year <- substr(returns$Year, 1, 4) #Ask what is going on here
returns <- aggregate(.~Year, data = returns, mean)
rf$Year <- substr(rf$Year,1,4)
rf <- aggregate(.~Year, data= rf, mean)
#Kick off the last row so that we have same sized datasets.
BE <- BE[1:89,]
size <- size[1:89,]
rf <- rf[1:89,]
# separate year from month in "size" dataframe
#size$Year2 <- substr(size$Year, 1, 4)
#size$Month <- substr(size$Year, 5, 6)
# separate year from month in "returns" dataframe
#returns$Year2 <- substr(size$Year, 1, 4)
#returns$Month <- substr(size$Year, 5, 6)
# make an average by year for "size" dataframe
#table(size[size$Year2 == "1926",])
#apply(size[size$Year2 == "1926",], 2, mean)
#size[size$Year2 == "1926",]
#data.frame(size[], apply(size[,c(2:50)],2, mean) )
#table(size$Year2)
BE <- melt(BE, id = c("Year"))
BE$Ind <- BE$variable
BE$variable <- NULL
BE$BEMERatio <- BE$value
BE$value <- NULL
size <- melt(size, id = c("Year"))
size$size <- size$value
size$value <- NULL
size$Ind <- size$variable
size$variable <- NULL
returns <- melt(returns, id = c("Year"))
returns$returns <- returns$value
returns$value <- NULL
returns$Ind <- returns$variable
size$variable <- NULL
size$YearInd <- paste(size$Year, size$Ind, sep = "_")
BE$YearInd <- paste(BE$Year, BE$Ind, sep = "_")
returns$YearInd <- paste(returns$Year, BE$Ind, sep = "_")
df <- merge(size, BE, by = "YearInd")
df <- merge(df, returns, by = "YearInd")
df$YearInd <- NULL
df$Year.y <- NULL
df$Ind.y <- NULL
df$variable <- NULL
df$Year <- NULL
df$Ind.x <- NULL
names(df)[1] <- "Year"
df$CompInd <- recode(df$Ind, "'Hlth' = 'Healthcare'; 'MedEq' = 'Healthcare'; 'Drugs' = 'Healthcare'; 'Chems' = 'Healthcare'; 'LabEq' = 'Healthcare'; 'Rubbr' = 'Industrials'; 'BldMt' = 'Industrials'; 'Cnstr' = 'Industrials'; 'Mach' = 'Industrials'; 'ElcEq' = 'Industrials'; 'Autos' = 'Industrials'; 'Aero' = 'Industrials'; 'Ships' = 'Industrials'; 'Mines' = 'Industrials'; 'FabPr' = 'Industrials'; 'Fun' = 'TMT'; 'Telcm' = 'TMT'; 'PerSv' = 'TMT'; 'BusSv' = 'TMT'; 'Softw' = 'TMT'; 'Chips' = 'TMT'; 'Paper' = 'TMT'; 'Banks' = 'Financials'; 'Insur' = 'Financials'; 'RlEst' = 'Financials'; 'Fin' = 'Financials'; 'Food' = 'Consumer'; 'Soda' = 'Consumer'; 'Beer' = 'Consumer'; 'Smoke' = 'Consumer'; 'Books' = 'Consumer'; 'Clths' = 'Consumer'; 'Hshld' = 'Consumer'; 'Meals' = 'Consumer'; 'Rtail' = 'Consumer'; 'Util' = 'Utilities'; 'Gold' = 'Commodities'; 'Coal' = 'Commodities'; 'Oil' = 'Commodities'; 'Steel' = 'Commodities'; 'Txtls' = 'Commodities'; 'Other' = 'Other'; 'Trans' = 'Other'; 'Boxes' = 'Other'; 'Guns' = 'Other'; 'Whlsl' = 'Other'; 'Agric' = 'Other'; 'Toys' = 'Other'")
View(df)
View(rf)
#Use the myResPlots2 function to evaluate model assumptions for mod1.
myResPlots2(mod1, label = "Firearm Fatality Rate by Grade")
knitr::opts_chunk$set(echo = TRUE)
library(reshape)
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
BE <- read.csv("Average BE .csv")
size <- read.csv("Average Firm Size Monthly.csv")
returns <- read.csv("Average Weighted Returns Monthly.csv")
rf <- read.csv("RP-RF.csv")
#BE <- BE[complete.cases(BE),]
#size <- size[complete.cases(size),]
#returns <- returns[complete.cases(returns),]
BE[BE== -99.99] <- 0
size[size == -99.99] <- 0
returns[returns == -99.99] <- 0
rf[rf == -99.99] <- 0
View(returns)
size$Year <- substr(size$Year, 1, 4) #Strip off all ofthe month values
size <- aggregate(.~Year, data = size, mean)
returns$Year <- substr(returns$Year, 1, 4) #Ask what is going on here
returns <- aggregate(.~Year, data = returns, mean)
rf$Year <- substr(rf$Year,1,4)
rf <- aggregate(.~Year, data= rf, mean)
rf$mktret <- rf$Mkt.RF+rf$RF #This creates the column for market return - done by adding back the risk free rate to the risk free market return
#Kick off the last row so that we have same sized datasets.
BE <- BE[1:89,]
size <- size[1:89,]
rf <- rf[1:89,]
View(rf)
View(BE)
BE <- melt(BE, id = c("Year"))
BE$Ind <- BE$variable
BE$variable <- NULL
BE$BEMERatio <- BE$value
BE$value <- NULL
size <- melt(size, id = c("Year"))
size$size <- size$value
size$value <- NULL
size$Ind <- size$variable
size$variable <- NULL
size <- melt(size, id = c("Year"))
size$size <- size$value
size$value <- NULL
size$Ind <- size$variable
size$variable <- NULL
returns <- melt(returns, id = c("Year"))
returns$returns <- returns$value
returns$value <- NULL
returns$Ind <- returns$variable
size$variable <- NULL
size$YearInd <- paste(size$Year, size$Ind, sep = "_")
BE$YearInd <- paste(BE$Year, BE$Ind, sep = "_")
returns$YearInd <- paste(returns$Year, BE$Ind, sep = "_")
df <- merge(size, BE, by = "YearInd")
df <- merge(df, returns, by = "YearInd")
df$YearInd <- NULL
df$Year.y <- NULL
df$Ind.y <- NULL
df$variable <- NULL
df$Year <- NULL
df$Ind.x <- NULL
names(df)[1] <- "Year"
df$CompInd <- recode(df$Ind, "'Hlth' = 'Healthcare'; 'MedEq' = 'Healthcare'; 'Drugs' = 'Healthcare'; 'Chems' = 'Healthcare'; 'LabEq' = 'Healthcare'; 'Rubbr' = 'Industrials'; 'BldMt' = 'Industrials'; 'Cnstr' = 'Industrials'; 'Mach' = 'Industrials'; 'ElcEq' = 'Industrials'; 'Autos' = 'Industrials'; 'Aero' = 'Industrials'; 'Ships' = 'Industrials'; 'Mines' = 'Industrials'; 'FabPr' = 'Industrials'; 'Fun' = 'TMT'; 'Telcm' = 'TMT'; 'PerSv' = 'TMT'; 'BusSv' = 'TMT'; 'Softw' = 'TMT'; 'Chips' = 'TMT'; 'Paper' = 'TMT'; 'Banks' = 'Financials'; 'Insur' = 'Financials'; 'RlEst' = 'Financials'; 'Fin' = 'Financials'; 'Food' = 'Consumer'; 'Soda' = 'Consumer'; 'Beer' = 'Consumer'; 'Smoke' = 'Consumer'; 'Books' = 'Consumer'; 'Clths' = 'Consumer'; 'Hshld' = 'Consumer'; 'Meals' = 'Consumer'; 'Rtail' = 'Consumer'; 'Util' = 'Utilities'; 'Gold' = 'Commodities'; 'Coal' = 'Commodities'; 'Oil' = 'Commodities'; 'Steel' = 'Commodities'; 'Txtls' = 'Commodities'; 'Other' = 'Other'; 'Trans' = 'Other'; 'Boxes' = 'Other'; 'Guns' = 'Other'; 'Whlsl' = 'Other'; 'Agric' = 'Other'; 'Toys' = 'Other'")
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(reshape)
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
BE <- read.csv("Average BE .csv")
size <- read.csv("Average Firm Size Monthly.csv")
returns <- read.csv("Average Weighted Returns Monthly.csv")
rf <- read.csv("RP-RF.csv")
#BE <- BE[complete.cases(BE),]
#size <- size[complete.cases(size),]
#returns <- returns[complete.cases(returns),]
BE[BE== -99.99] <- 0
size[size == -99.99] <- 0
returns[returns == -99.99] <- 0
rf[rf == -99.99] <- 0
size$Year <- substr(size$Year, 1, 4) #Strip off all ofthe month values
size <- aggregate(.~Year, data = size, mean)
returns$Year <- substr(returns$Year, 1, 4) #Ask what is going on here
returns <- aggregate(.~Year, data = returns, mean)
rf$Year <- substr(rf$Year,1,4)
rf <- aggregate(.~Year, data= rf, mean)
rf$mktret <- rf$Mkt.RF+rf$RF #This creates the column for market return - done by adding back the risk free rate to the risk free market return
#Kick off the last row so that we have same sized datasets.
BE <- BE[1:89,]
size <- size[1:89,]
rf <- rf[1:89,]
# separate year from month in "size" dataframe
#size$Year2 <- substr(size$Year, 1, 4)
#size$Month <- substr(size$Year, 5, 6)
# separate year from month in "returns" dataframe
#returns$Year2 <- substr(size$Year, 1, 4)
#returns$Month <- substr(size$Year, 5, 6)
# make an average by year for "size" dataframe
#table(size[size$Year2 == "1926",])
#apply(size[size$Year2 == "1926",], 2, mean)
#size[size$Year2 == "1926",]
#data.frame(size[], apply(size[,c(2:50)],2, mean) )
#table(size$Year2)
BE <- melt(BE, id = c("Year"))
BE$Ind <- BE$variable
BE$variable <- NULL
BE$BEMERatio <- BE$value
BE$value <- NULL
size <- melt(size, id = c("Year"))
size$size <- size$value
size$value <- NULL
size$Ind <- size$variable
size$variable <- NULL
returns <- melt(returns, id = c("Year"))
returns$returns <- returns$value
returns$value <- NULL
returns$Ind <- returns$variable
size$variable <- NULL
size$YearInd <- paste(size$Year, size$Ind, sep = "_")
BE$YearInd <- paste(BE$Year, BE$Ind, sep = "_")
returns$YearInd <- paste(returns$Year, BE$Ind, sep = "_")
df <- merge(size, BE, by = "YearInd")
df <- merge(df, returns, by = "YearInd")
df$YearInd <- NULL
df$Year.y <- NULL
df$Ind.y <- NULL
df$variable <- NULL
df$Year <- NULL
df$Ind.x <- NULL
names(df)[1] <- "Year"
View(df)
a<- merge(df, rf, by = "Year")
View(a)
df <- merge(df, rf, by = "Year")
View(df)
?tapply
df$Year <- as.factor(df$Year)
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
source("http://www.reuningscherer.net/s&ds230/Rfuncs/regJDRS.txt")
#Get dataset
guns <- read.csv("http://reuningscherer.net/s&ds230/data/Guns_2017.csv", as.is = TRUE)
#Get dimension, top six rows, and variable names of guns
dim(guns)
head(guns)
names(guns)
#Define the URL of interest
url <- "http://www.gunsandammo.com/second-amendment/best-states-for-gun-owners-2017/"
#Read the HTML code from website into a new object
webpage <- read_html(url)
#Get rankings and strip off extraneous information.   Sort rankings so that they are in state alphabetical order so that you can merge this information onto the guns object.  Use whatever code you like for this.  The argument you want to use in the html_nodes function is 'p strong'
#Code here.   End up with code below
gunRanking <-  html_nodes(webpage,'p strong')
gunRanking <- html_text(gunRanking)
gunRanking <- gunRanking[c(2,4,6:53)]
gunRanking <- trimws(gunRanking)
gunRanking <- gsub(".*[.]", "", gunRanking)
gunRanking <- trimws(gunRanking)
gunRanking <- c(50:1)[order(gunRanking)]
#Create ammoRank variable.  This should be an INTEGER variable.
guns$ammoRank <- as.integer(gunRanking)
#Create new variable called Grade such that GiffordsGrade is recoded as follows:
#  Any form of A or B becomes 'AB'
#  Any form of C or D becomes 'CD'
#  F stays at F
guns$Grade <- recode(guns$GiffordsGrade, "'A' = 'AB'; 'A-' = 'AB'; 'B' = 'AB'; 'B+' = 'AB'; 'C' = 'CD'; 'C-' = 'CD'; 'C+' = 'CD'; 'D' = 'CD'; 'D-' = 'CD'; 'F' = 'F'")
#Change median income so that it is in thousands of dollars, not dollars.
guns$median.inc <- (guns$median.inc)/1000
#Create a variable that is the natural log of lawtotal.
guns$loglaws <- log(guns$lawtotal)
#Create a boxplot of rate_16 by Grade.  Add a title and change the color.
boxplot(guns$rate_16~guns$Grade, main = "Boxplot of Firearm Fatality Rate per 100k in 2016 by Grade", xlab = "Grade", ylab = "Fatality Rate per 100k", col = "orange")
#Calculate the standard deviation of rate_16 for each grade group
#print("SD by Genre")
(sds <- tapply(guns$rate_16, guns$Grade, sd))
#Get ratio of max to min sample standard deviation by Grade and round to one decimal place.
#print("Ratio of Max/Min Sample SD")
round(max(sds)/min(sds),1)
#Based on previous calculation, is the equal variance assumption of ANOVA reasonably met?  yes or no
(q104 <- "yes") #Ratio is less than two, so the equal variance assumption is reasonably met
#Calculate a one-way ANOVA comparing mean rate_16 by Grade.  Use the aov() function.
(mod1 <- aov(guns$rate_16 ~ guns$Grade))
#Get summary of mod1
summary(mod1)
#Create Tukey confidence intervals for all pairs of groups.
TukeyHSD(mod1)
#Plot Tukey Confidence intervals.
plot(TukeyHSD(mod1), las=1)
#Use the myResPlots2 function to evaluate model assumptions for mod1.
myResPlots2(mod1, label = "Firearm Fatality Rate by Grade")
#Do the residuals seem approximately normally distributed?
#Does the plot of fits vs. residuals indicate any model lack of fit?
(q110 <- c("yes","no"))
#Perform a Kruskal-Wallis test to compare rate_16 based on Grade
kruskal.test(rate_16 ~ as.factor(Grade), data = guns)
#Fit a regression predicting lawtotal based on median.inc and ammoRank
(mod2 <- lm(lawtotal ~ median.inc + ammoRank, data = guns))
#Get summary information for mod2
summary(mod2)
#Run a Box Cox procedure on model q211
trans1 <- boxCox(mod2)
trans1$x[which.max(trans1$y)]
#What is a reasonable suggested value for lambda?  Replace 'lambda' below with a number.
(q214 <- c(0)) #The transformation we will make is a natural log because 0 is included in the confidence interval
#Fit a regression model predicting the transformed version of lawtotal suggested by the Box Cox Transformation.
#  Again, median.inc and ammmoRank are the two predictors.
(mod3 <- lm(log(lawtotal) ~ median.inc + ammoRank, data = guns)) #Review
#Get summary information for model mod3.
summary(mod3)
#Are both predictors statistically significant at the 0.05 level?
(q217 <- c("yes"))
#According to the model mod3, as ammoRank increases, does the number of laws increase or decrease?
(q218 <- c("increase"))
#use myResPlots2 to get residual plots for this model.
myResPlots2(mod3, label = "Log(Law) by Median Inc and Ammo Rank")
#create an object q301 that only has the following columns of guns : rate_16, median.inc, loglaws, LawRanking, ammoRank.
q301 <- guns[,c("rate_16","median.inc","loglaws","LawRanking", "ammoRank")]
#Get correlations for the variables in q301 and round to two decimal places.
(round(cor(q301), 2))
#Create an object that has the results of cor.mtest for the columns of q301.  Use 95% CI.
(q303 <- cor.mtest(q301, conf.level = .95))
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values for the columns in q302.
corrplot.mixed(cor(q301), lower.col="black", upper = "ellipse", tl.col = "black", number.cex=.7, tl.pos = "lt", tl.cex=.7, p.mat = q303$p, sig.level = .05)
#Are the correlations you observe relatively strong or relatively weak?
(q305 <- c("relatively strong"))
#Use the parisJDRS() function on the columns of q301.
(q306 <- pairsJDRS(q301, labels = names(q301)))
names(guns)
#Create a dataframe guns2 from guns that removes state, code, rate_05, lawtotal, GiffordsGrade, Grade.
guns2 <- guns[,-c(1,2,4,25,27,29)]
#Run bests subsets to predict rate_16 based on all other columns in guns2 - use regsubsets() function.
(q401 <- regsubsets(rate_16 ~ ., data = guns2, nvmax = 23))
#Get summary information for q401
q402 <- summary(q401)
#Get the which matrix from the summary in the previous question.
(q403 <-  q402$which)
#If you were to fit a model with only one predictor, which predictor would this be? CHANGE TEXT BELOW.
(q404 <- c("loglaws"))
# Get the best model according to the Bayesian Information Criteria (BIC)
(q405 <- which.min(q402$bic))
#Which variables are in this model?  Can code from names or use quoted string.
names(guns2)[q402$which[which.min(q402$bic),]][-1]
#names(guns2)[q402$which[q405,]][-1]
#Fit the model suggested by BIC and save to q407
guntemp <- guns2[,q402$which[which.min(q402$bic),]]
#guntemp <- guns2[,q402$which[q405,]]
(q407 <- lm(rate_16 ~ .,data=guntemp))
#Get summary info for model q407
summary(q407)
#Run myResPlots2 on model q407
myResPlots2(q407, label="Firearm Fatality per 100,000 (2016)")
#Are the model assumptions reasonably met?
(q409 <- c("yes"))
temp <- df[df$Ind == "Aero",]
View(temp)
df$Year <- as.factor(df$Year)
df$Beta <- NA
knitr::opts_chunk$set(echo = TRUE)
library(reshape)
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
BE <- read.csv("Average BE .csv")
size <- read.csv("Average Firm Size Monthly.csv")
returns <- read.csv("Average Weighted Returns Monthly.csv")
rf <- read.csv("RP-RF.csv")
#BE <- BE[complete.cases(BE),]
#size <- size[complete.cases(size),]
#returns <- returns[complete.cases(returns),]
BE[BE== -99.99] <- 0
size[size == -99.99] <- 0
returns[returns == -99.99] <- 0
rf[rf == -99.99] <- 0
size$Year <- substr(size$Year, 1, 4) #Strip off all ofthe month values
size <- aggregate(.~Year, data = size, mean)
returns$Year <- substr(returns$Year, 1, 4) #Ask what is going on here
returns <- aggregate(.~Year, data = returns, mean)
rf$Year <- substr(rf$Year,1,4)
rf <- aggregate(.~Year, data= rf, mean)
rf$mktret <- rf$Mkt.RF+rf$RF #This creates the column for market return - done by adding back the risk free rate to the risk free market return
#Kick off the last row so that we have same sized datasets.
BE <- BE[1:89,]
size <- size[1:89,]
rf <- rf[1:89,]
# separate year from month in "size" dataframe
#size$Year2 <- substr(size$Year, 1, 4)
#size$Month <- substr(size$Year, 5, 6)
# separate year from month in "returns" dataframe
#returns$Year2 <- substr(size$Year, 1, 4)
#returns$Month <- substr(size$Year, 5, 6)
# make an average by year for "size" dataframe
#table(size[size$Year2 == "1926",])
#apply(size[size$Year2 == "1926",], 2, mean)
#size[size$Year2 == "1926",]
#data.frame(size[], apply(size[,c(2:50)],2, mean) )
#table(size$Year2)
BE <- melt(BE, id = c("Year"))
BE$Ind <- BE$variable
BE$variable <- NULL
BE$BEMERatio <- BE$value
BE$value <- NULL
size <- melt(size, id = c("Year"))
size$size <- size$value
size$value <- NULL
size$Ind <- size$variable
size$variable <- NULL
returns <- melt(returns, id = c("Year"))
returns$returns <- returns$value
returns$value <- NULL
returns$Ind <- returns$variable
size$variable <- NULL
size$YearInd <- paste(size$Year, size$Ind, sep = "_")
BE$YearInd <- paste(BE$Year, BE$Ind, sep = "_")
returns$YearInd <- paste(returns$Year, BE$Ind, sep = "_")
df <- merge(size, BE, by = "YearInd")
df <- merge(df, returns, by = "YearInd")
df$YearInd <- NULL
df$Year.y <- NULL
df$Ind.y <- NULL
df$variable <- NULL
df$Year <- NULL
df$Ind.x <- NULL
names(df)[1] <- "Year"
df$CompInd <- recode(df$Ind, "'Hlth' = 'Healthcare'; 'MedEq' = 'Healthcare'; 'Drugs' = 'Healthcare'; 'Chems' = 'Healthcare'; 'LabEq' = 'Healthcare'; 'Rubbr' = 'Industrials'; 'BldMt' = 'Industrials'; 'Cnstr' = 'Industrials'; 'Mach' = 'Industrials'; 'ElcEq' = 'Industrials'; 'Autos' = 'Industrials'; 'Aero' = 'Industrials'; 'Ships' = 'Industrials'; 'Mines' = 'Industrials'; 'FabPr' = 'Industrials'; 'Fun' = 'TMT'; 'Telcm' = 'TMT'; 'PerSv' = 'TMT'; 'BusSv' = 'TMT'; 'Softw' = 'TMT'; 'Chips' = 'TMT'; 'Paper' = 'TMT'; 'Banks' = 'Financials'; 'Insur' = 'Financials'; 'RlEst' = 'Financials'; 'Fin' = 'Financials'; 'Food' = 'Consumer'; 'Soda' = 'Consumer'; 'Beer' = 'Consumer'; 'Smoke' = 'Consumer'; 'Books' = 'Consumer'; 'Clths' = 'Consumer'; 'Hshld' = 'Consumer'; 'Meals' = 'Consumer'; 'Rtail' = 'Consumer'; 'Util' = 'Utilities'; 'Gold' = 'Commodities'; 'Coal' = 'Commodities'; 'Oil' = 'Commodities'; 'Steel' = 'Commodities'; 'Txtls' = 'Commodities'; 'Other' = 'Other'; 'Trans' = 'Other'; 'Boxes' = 'Other'; 'Guns' = 'Other'; 'Whlsl' = 'Other'; 'Agric' = 'Other'; 'Toys' = 'Other'")
df <- merge(df, rf, by = "Year")
df$Year <- as.factor(df$Year)
df$Beta <- NA
for(i in unique(df$Ind)){
temp <- df[df$Ind == i,]
a <- (cov(temp$returns,temp$mktret))/(var(temp$mktret))
df$Beta[df$Ind==i,] <- a
}
for(i in unique(df$Ind)){
temp <- df[df$Ind == i,]
a <- (cov(temp$returns,temp$mktret))/(var(temp$mktret))
df$Beta[df$Ind==i] <- a
}
View(df)
